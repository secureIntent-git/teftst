---
ID: 2231
post_title: >
  MIT’s Clever New Drone Draws What You
  Do. Mostly
author: Staff Writer
post_date: 2016-03-27 22:04:11
post_excerpt: ""
layout: post
permalink: >
  https://www.whenitson.com/mits-clever-new-drone-draws-what-you-do-mostly/
published: true
original_cats:
  - Design
original_title:
  - >
    MIT’s Clever New Drone Draws What You
    Do. Mostly
original_link:
  - >
    http://feeds.wired.com/c/35185/f/661370/s/4e8982bd/sc/23/l/0L0Swired0N0C20A160C0A30Cmits0Eclever0Enew0Edrone0Edraws0Emostly0C/story01.htm
canonical_url:
  - >
    http://feeds.wired.com/c/35185/f/661370/s/4e8982bd/sc/23/l/0L0Swired0N0C20A160C0A30Cmits0Eclever0Enew0Edrone0Edraws0Emostly0C/story01.htm
---
 [ad_1]
<br><div id=""><p>Humans have always used tools to create art, but paintbrushes, pens, and chisels don’t have an agenda of their own; they bend to the will of the person wielding them. But a project by students at the MIT Media Lab’s Fluid Interfaces Group ponders what happens when a machine has a voice in the artistic process.</p>
<p>In this case, the machine is a drone, and that drone is essentially a flying <a href="https://en.wikipedia.org/wiki/Pantograph" target="_blank">phantograph</a>. As a human draws with a pen, a camera captures the motion and a computer communicates it to the drone, which mimics what the pen is drawing.</p>
<p><iframe src="https://player.vimeo.com/video/157484947?color=ffffff&amp;title=0&amp;byline=0&amp;portrait=0" width="582" height="327" frameborder="0" allowfullscreen="allowfullscreen"/></p>
<p>In the video you see a person make a sweeping gesture across a canvas with the pen; the drone mirrors it, creating a similar mark on its own canvas. It isn’t without hiccups. “When a pen attached to the drone comes in contact with the canvas, the pressure applied towards the canvas induces a sideway friction,” the team writes it its <a href="http://fluid.media.mit.edu/sites/default/files/p653-leigh.pdf" target="_blank">paper</a>. Sang Leigh, one of the researchers, says the first-generation drone was less controlled, giving it a squiggly aesthetic. “Now we have better control capacity so that we can fairly easily draw straight lines,” he says. Still, he adds, “there is huge room for engineering, to be fair.”</p>
<p>Some of the visual discrepancies were intentional. The drone could be programmed to interpret a human’s drawing on a smaller or larger scale. The drawing could be mirrored (to the best of the drone’s ability) in real time, or the drone could be programmed with an intentional time delay. Other variables were simply reflected the state of the technology. The drone seems to read slow, deliberate movements more accurately, while longer or faster strokes introduce errors.</p>
<p>The researchers seemed to have embraced the system’s unpredictability. While some might say it’s a technical shortcoming, the team sees the inconsistencies created by algorithms and aerodynamics as a distinctive visual style. “From an art perspective, we found this very fascinating,” Leigh says. He argues that, like artist Jackson Pollock’s abstract dripping pieces, the machine’s dynamic unpredictability adds fascinating aesthetics. “In this we found room for machine creativity seeping into the artistic act of a human,” he says.</p>

			<a class="visually-hidden skip-to-text-link focusable bg-white" href="#start-of-content">Go Back to Top. Skip To: Start of Article.</a>

					</div>
<br>[ad_2]
<br><a href="http://feeds.wired.com/c/35185/f/661370/s/4e8982bd/sc/23/l/0L0Swired0N0C20A160C0A30Cmits0Eclever0Enew0Edrone0Edraws0Emostly0C/story01.htm">Source </a>