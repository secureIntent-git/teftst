---
ID: 3032
post_title: >
  The Average Webpage Is Now the Size of
  the Original Doom
author: Staff Writer
post_date: 2016-04-24 10:27:04
post_excerpt: ""
layout: post
permalink: >
  https://www.whenitson.com/the-average-webpage-is-now-the-size-of-the-original-doom/
published: true
original_cats:
  - >
    Business,Broadband,Comcast,developers,The
    Web
original_title:
  - >
    The Average Webpage Is Now the Size of
    the Original Doom
original_link:
  - >
    http://www.wired.com/2016/04/average-webpage-now-size-original-doom/
canonical_url:
  - >
    http://www.wired.com/2016/04/average-webpage-now-size-original-doom/
---
 [ad_1]
<br><div id=""><figure attachment_2007176="" class="wp-caption landscape alignnone  relative" data-js="fader"><a href="https://www.wired.com/wp-content/uploads/2016/04/Doom_1280w.jpg"><img src="http://www.whenitson.com/wp-content/uploads/2016/04/The-Average-Webpage-Is-Now-the-Size-of-the-Original-Doom.jpg" alt="Doom_1280w.jpg" width="582" height="327" class="size-default-top-art wp-image-2007176"/></a><figcaption class="wp-caption-text link-underline"><span class="credit link-underline-sm"><span aria-hidden="true" class="ui ui ui-photo inline-block ui-credit relative opacity-6 marg-r-sm marg-l-sm no-caption"/>ID Software</span></figcaption></figure><p>The web is <em>Doom</em>ed.</p>
<p>Today the average webpage is about the same size, data-wise, as the classic computer game <em>Doom</em>, <a href="https://mobiforge.com/research-analysis/the-web-is-doom">according to software engineer Ronan Cremin</a>. </p>
<p>A compressed copy of the installer for the <a href="http://www.doomworld.com/classicdoom/info/shareware.php">shareware version of <em>Doom</em></a> takes up about 2.39MB of space. Today’s average webpage, meanwhile, requires users to download about 2.3MB worth of data, according to <a href="http://www.httparchive.org/interesting.php?a=All&amp;l=Apr%201%202016">HTTP Archive</a>, a site that tracks website performance and the technologies they use.</p>



<p>That’s not totally analogous comparison, but it does illustrate the web’s growing obesity problem. “Recall that Doom is a multi-level first person shooter that ships with an advanced 3D rendering engine and multiple levels, each comprised of maps, sprites, and sound effects,” Cremin writes on MobiForge, a site for mobile web developers. “By comparison, 2016’s web struggles to deliver a page of web content in the same size.”</p>
<p>Many sites are even larger than the average. WIRED’s homepage is about 7.8MB, which would take six 1.44MB floppy disks to store. Individual pages are a bit lighter—our <a href="http://www.wired.com/2015/11/i-turned-off-javascript-for-a-whole-week-and-it-was-glorious/">story on giving up JavaScript for a week</a> weighs in at just 3MB—but are still big enough to require multiple disks.</p>
<p>So how did we get here? As internet connections have gotten faster, publishers and developers worry less about efficiency. That’s led to a growing number of analytics scripts, animated ads, and high-resolution photographs. Each individual script may be small, but eventually they add up, slowing down page loads not just by adding bulk but by increasing the number of connections required to load a page.</p>
<p>Apart from being inefficient–and potentially violating users’ privacy–this massive growth in page size could wind up costing users money. Wireless internet providers have been phasing out unlimited data plans for years, and even <a href="http://www.wired.com/2015/11/sorry-theres-no-such-thing-as-unlimited-data/">unlimited plans tend to throttle speeds</a> after users hit a certain download limit. Fixed line internet providers like Comcast are also imposing bandwidth limits, which means that one day soon every megabyte might count.</p>
<p data-js="fader" class="pullquote carve fader">
	As internet connections have gotten faster, publishers and developers worry less about efficiency.	<span class="attribution"/>
</p>

<p>Bloated pages also make sites dreadfully slow to load for users on slower connections, such as the <a href="http://time.com/3856066/aol-verizon-deal-dial-up-internet/">2.3 million people</a> who as of last year still used AOL dial-up, or those living in developing countries–not to mention people who have high-speed LTE connections on their phones but just happen to be in a spot with bad reception.</p>
<p>The good news, according to Cremin’s research, is that the top 10 most popular sites <a href="http://www.alexa.com/topsites">based on Alexa’s rankings</a> are significantly lighter than the average page, and they’re getting lighter every month. If these popular sites are trendsetters, we should expect other sites to follow.</p>
<p>Meanwhile, organizations ranging from <a href="http://www.wired.com/2016/02/googles-amp-speeding-web-changing-works/">Google</a> and <a href="http://www.wired.com/2015/05/instant-articles-facebook-shows-us-paper/">Facebook</a> to <a href="http://www.wired.com/2016/03/mit-polaris-faster-web-pages/">MIT</a> are working on new technologies to speed pages up. Each approach has its drawbacks—for example, you have to host your content on Google’s servers to take full advantage of <a href="http://www.wired.com/2015/10/googles-got-plan-make-mobile-web-less-slow/" target="_blank">its Accelerated Mobile Pages program, or AMP</a>. But the message is clear: it’s time for the web to burn some fat to avoid certain DOOM.</p>

			<a class="visually-hidden skip-to-text-link focusable bg-white" href="#start-of-content">Go Back to Top. Skip To: Start of Article.</a>

		</div>
<br>[ad_2]
<br><a href="http://www.wired.com/2016/04/average-webpage-now-size-original-doom/">Source </a>