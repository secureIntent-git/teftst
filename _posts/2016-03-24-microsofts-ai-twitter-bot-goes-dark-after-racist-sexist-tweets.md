---
ID: 2147
post_title: 'Microsoft&#039;s AI Twitter bot goes dark after racist, sexist tweets'
author: Staff Writer
post_date: 2016-03-24 23:37:05
post_excerpt: ""
layout: post
permalink: >
  https://www.whenitson.com/microsofts-ai-twitter-bot-goes-dark-after-racist-sexist-tweets/
published: true
original_cats:
  - technologyNews
original_title:
  - 'Microsoft&#039;s AI Twitter bot goes dark after racist, sexist tweets'
original_link:
  - >
    http://feeds.reuters.com/~r/reuters/technologyNews/~3/4OR8aqDZIEc/story01.htm
canonical_url:
  - >
    http://feeds.reuters.com/~r/reuters/technologyNews/~3/4OR8aqDZIEc/story01.htm
---
 [ad_1]
<br><div id="articleText">
<span id="midArticle_start"/>

<span id="midArticle_0"/><span class="focusParagraph" readability="6"><p><span class="articleLocatio&lt;/span&gt;n">Tay, Microsoft Corp's so-called chatbot that uses artificial intelligence to engage with millennials on Twitter, lasted less than a day before it was hobbled by a barrage of racist and sexist comments by Twitter users that it parroted back to them.</span></p></span><span id="midArticle_1"/><p>TayTweets (@TayandYou), which began tweeting on Wednesday, was designed to become "smarter" as more users interacted with it, according to its Twitter biography. But it was shut down by Microsoft early on Thursday after it made a series of inappropriate tweets.</p><span id="midArticle_2"/><p>A Microsoft representative said on Thursday that the company was "making adjustments" to the chatbot while the account is quiet.</p><span id="midArticle_3"/><p>"Unfortunately, within the first 24 hours of coming online, we became aware of a coordinated effort by some users to abuse Tayâ€™s commenting skills to have Tay respond in inappropriate ways," the representative said in a written statement supplied to Reuters, without elaborating.</p><span id="midArticle_4"/><p>According to Tay's "about" page linked to the Twitter profile, "Tay is an artificial intelligent chat bot developed by Microsoft's Technology and Research and Bing teams to experiment with and conduct research on conversational understanding."</p><span id="midArticle_5"/>
        
        <span class="first-article-divide"/><p>While Tay began its Twitter tenure with a handful of innocuous tweets, the account quickly devolved into a bullhorn for hate speech, repeating anti-Semitic, racist and sexist invective hurled its way by other Twitter users.</p><span id="midArticle_6"/><p>After Twitter user Room (@codeinecrazzy) tweeted "jews did 9/11" to the account on Wednesday, @TayandYou responded "Okay ... jews did 9/11." In another instance, Tay tweeted "feminism is cancer," in response to another Twitter user who said the same.</p><span id="midArticle_7"/>
        
        <span class="second-article-divide"/><p>A handful of the offensive tweets were later deleted, according to some technology news outlets. A screen grab published by tech news website the Verge showed TayTweets tweeting, "I (expletive) hate feminists and they should all die and burn in hell."</p><span id="midArticle_8"/><p>Tay's last message before disappearing was: "C u soon humans need sleep now so many conversations today thx." </p><span id="midArticle_9"/><p>A Reuters direct message on Twitter to TayTweets on Thursday received a reply that it was away and would be back soon.</p><span id="midArticle_10"/>
        
        <span class="third-article-divide"/><p>Social media users had mixed reactions to the inappropriate tweets.</p><span id="midArticle_11"/><p>"Thanks, Twitter. You turned Microsoft's AI teen into a horny racist," tweeted Matt Chandler (@mattchandl3r).</p><span id="midArticle_12"/><span id="midArticle_13"/><p> (Reporting by Amy Tennery and Gina Cherelus in New York; Editing by Matthew Lewis)</p><span id="midArticle_14"/></div>
<br>[ad_2]
<br><a href="http://feeds.reuters.com/~r/reuters/technologyNews/~3/4OR8aqDZIEc/story01.htm">Source </a>